{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_events = spark.read.format(\"kafka\").option(\"kafka.bootstrap.servers\", \"kafka:29092\").option(\"subscribe\",\"events\").option(\"startingOffsets\", \"earliest\").option(\"endingOffsets\", \"latest\").load() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "events = raw_events.select(raw_events.value.cast('string'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/spark-2.2.0-bin-hadoop2.6/python/pyspark/sql/session.py:351: UserWarning: Using RDD of dict to inferSchema is deprecated. Use pyspark.sql.Row instead\n",
      "  warnings.warn(\"Using RDD of dict to inferSchema is deprecated. \"\n"
     ]
    }
   ],
   "source": [
    "extracted_events = events.rdd.map(lambda x: json.loads(x.value)).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+-----------+--------------+\n",
      "|Accept|          Host| User-Agent|    event_type|\n",
      "+------+--------------+-----------+--------------+\n",
      "|   */*|localhost:5000|curl/7.47.0|       default|\n",
      "|   */*|localhost:5000|curl/7.47.0|purchase_sword|\n",
      "|   */*|localhost:5000|curl/7.47.0|purchase_knife|\n",
      "|   */*|localhost:5000|curl/7.47.0| purchase_frog|\n",
      "|   */*|localhost:5000|curl/7.47.0|    ride_horse|\n",
      "|   */*|localhost:5000|curl/7.47.0|climb_mountain|\n",
      "|   */*|localhost:5000|curl/7.47.0|    ride_horse|\n",
      "|   */*|localhost:5000|curl/7.47.0| purchase_frog|\n",
      "+------+--------------+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extracted_events.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extracted_events \\\n",
    "        .write \\\n",
    "        .parquet(\"/tmp/extracted_events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                 raw|           timestamp|              munged|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|{\"Host\": \"localho...|2019-11-10 05:04:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"localho...|2019-11-10 05:05:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"localho...|2019-11-10 05:06:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"localho...|2019-11-10 05:07:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"localho...|2019-11-10 05:07:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"localho...|2019-11-10 05:07:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"localho...|2019-11-10 05:41:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"localho...|2019-11-10 05:42:...|{\"Host\": \"moe\", \"...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n",
      "+------+-------------+----+-----------+--------------+--------------------+\n",
      "|Accept|Cache-Control|Host| User-Agent|    event_type|           timestamp|\n",
      "+------+-------------+----+-----------+--------------+--------------------+\n",
      "|   */*|     no-cache| moe|curl/7.47.0|       default|2019-11-10 05:04:...|\n",
      "|   */*|     no-cache| moe|curl/7.47.0|purchase_sword|2019-11-10 05:05:...|\n",
      "|   */*|     no-cache| moe|curl/7.47.0|purchase_knife|2019-11-10 05:06:...|\n",
      "|   */*|     no-cache| moe|curl/7.47.0| purchase_frog|2019-11-10 05:07:...|\n",
      "|   */*|     no-cache| moe|curl/7.47.0|    ride_horse|2019-11-10 05:07:...|\n",
      "|   */*|     no-cache| moe|curl/7.47.0|climb_mountain|2019-11-10 05:07:...|\n",
      "|   */*|     no-cache| moe|curl/7.47.0|    ride_horse|2019-11-10 05:41:...|\n",
      "|   */*|     no-cache| moe|curl/7.47.0| purchase_frog|2019-11-10 05:42:...|\n",
      "+------+-------------+----+-----------+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@udf('string')\n",
    "def munge_event(event_as_json):\n",
    "    event = json.loads(event_as_json)\n",
    "    event['Host'] = \"moe\"\n",
    "    event['Cache-Control'] = \"no-cache\"\n",
    "    return json.dumps(event)\n",
    "\n",
    "raw_events = spark \\\n",
    "        .read \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", \"kafka:29092\") \\\n",
    "        .option(\"subscribe\", \"events\") \\\n",
    "        .option(\"startingOffsets\", \"earliest\") \\\n",
    "        .option(\"endingOffsets\", \"latest\") \\\n",
    "        .load()\n",
    "\n",
    "munged_events = raw_events \\\n",
    "    .select(raw_events.value.cast('string').alias('raw'),\n",
    "            raw_events.timestamp.cast('string')) \\\n",
    "    .withColumn('munged', munge_event('raw'))\n",
    "munged_events.show()\n",
    "\n",
    "extracted_events = munged_events \\\n",
    "    .rdd \\\n",
    "    .map(lambda r: Row(timestamp=r.timestamp, **json.loads(r.munged))) \\\n",
    "    .toDF()\n",
    "extracted_events.show()\n",
    "\n",
    "extracted_events \\\n",
    "    .write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .parquet(\"/tmp/extracted_events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+----+-----------+--------------+--------------------+\n",
      "|Accept|Cache-Control|Host| User-Agent|    event_type|           timestamp|\n",
      "+------+-------------+----+-----------+--------------+--------------------+\n",
      "|   */*|     no-cache| moe|curl/7.47.0|purchase_sword|2019-11-10 05:05:...|\n",
      "+------+-------------+----+-----------+--------------+--------------------+\n",
      "\n",
      "+------+-------------+----+-----------+----------+--------------------+\n",
      "|Accept|Cache-Control|Host| User-Agent|event_type|           timestamp|\n",
      "+------+-------------+----+-----------+----------+--------------------+\n",
      "|   */*|     no-cache| moe|curl/7.47.0|   default|2019-11-10 05:04:...|\n",
      "+------+-------------+----+-----------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# separate.py\n",
    "import json\n",
    "\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "@udf('string')\n",
    "def munge_event(event_as_json):\n",
    "    event = json.loads(event_as_json)\n",
    "    event['Host'] = \"moe\"\n",
    "    event['Cache-Control'] = \"no-cache\"\n",
    "    return json.dumps(event)\n",
    "\n",
    "raw_events = spark \\\n",
    "    .read \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:29092\") \\\n",
    "    .option(\"subscribe\", \"events\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .option(\"endingOffsets\", \"latest\") \\\n",
    "    .load()\n",
    "\n",
    "munged_events = raw_events \\\n",
    "    .select(raw_events.value.cast('string').alias('raw'),\n",
    "            raw_events.timestamp.cast('string')) \\\n",
    "    .withColumn('munged', munge_event('raw'))\n",
    "\n",
    "extracted_events = munged_events \\\n",
    "    .rdd \\\n",
    "    .map(lambda r: Row(timestamp=r.timestamp, **json.loads(r.munged))) \\\n",
    "    .toDF()\n",
    "\n",
    "sword_purchases = extracted_events \\\n",
    "    .filter(extracted_events.event_type == 'purchase_sword')\n",
    "sword_purchases.show()\n",
    "sword_purchases \\\n",
    "    .write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .parquet(\"/tmp/sword_purchases\")\n",
    "    \n",
    "default_hits = extracted_events \\\n",
    "    .filter(extracted_events.event_type == 'default')\n",
    "default_hits.show()\n",
    "default_hits \\\n",
    "    .write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .parquet(\"/tmp/default_hits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
